# 03-调度系统：“数据不动代码动”到底是什么意思？

![](https://static001.geekbang.org/resource/image/cc/ac/cc6ecb33072cfd63a1f77c58b79d81ac.jpg)

在日常的开发与调优工作中，为了充分利用硬件资源，我们往往需要手工调节任务并行度来提升 CPU 利用率，控制任务并行度的参数是 Spark 的配置项：spark.default.parallelism。增加并行度确实能够充分利用闲置的 CPU 线程，但是，parallelism 数值也不宜过大，过大反而会引入过多的调度开销，得不偿失。

这个调优技巧可以说是老生常谈了，网上到处都可以搜得到。那你知道为什么 parallelism 数值过大调度开销会呈指数级增长吗？调度开销具体又是指什么呢？以及，如果不想一个数值一个数值的尝试，parallelism 数值究竟该怎么设置，才能以最少的时间获得最好的效果？如果你还没有答案，或者说还没有把握答对，接下来你就要好好听我讲。

这一讲，我会通过一个机器学习案例，来和你一起聊聊调度系统是什么，它是怎么工作的，从而帮助你摆脱调优总是停留在知其然、不知其所以然的尴尬境地。

## 案例：对用户兴趣特征做 Label Encoding

在机器学习应用中，特征工程几乎占据了算法同学 80% 的时间和精力，毕竟，一份质量优良的训练样本限定了模型效果的上限和天花板，我们要讲的案例就来自特征工程中一个典型的处理场景：Label Encoding（标签编码）。

什么是 Label encoding 呢？模型特征按照是否连续可以分为两类：连续性数值特征和离散型特征，离散型特征往往以字符串的形式存在，比如用户兴趣特征就包括体育、政治、军事和娱乐等。对于很多机器学习算法来说，字符串类型的数据是不能直接消费的，需要转换为数值才行，例如把体育、政治、军事、娱乐映射为 0、1、2、3，这个过程在机器学习领域有个术语就叫 Label encoding。

我们这一讲的案例，就是要对用户兴趣特征做 Label encoding，简单来说就是以固定的模板把字符串转换为数值，然后将千亿条样本中的用户兴趣转换为对应的索引值。固定模板是离线模型训练与线上模型服务之间的文件接口，内容仅包含用户兴趣这一列，字符串已按事先约定好的规则进行排序。我们需要注意的是，用户兴趣包含 4 个层级，因此这个模板文件较大，记录数达到万级别。

```sh
//模板文件
//用户兴趣
体育-篮球-NBA-湖人
军事-武器-步枪-AK47
```

那具体怎么转换呢？例如，我们可以将用户兴趣“体育 - 篮球 -NBA- 湖人”映射为 0，将兴趣“军事 - 武器 - 步枪 -AK47”映射为 1，以此类推。应该说，需求还是相当明确的，我身边的同学们拿到需求之后，奔儿都没打，以迅雷不及掩耳之势就实现了如下的处理函数。

```scala
/**
	实现方式1
	输入参数：模板文件路径，用户兴趣字符串
	返回值：用户兴趣字符串对应的索引值
*/

//函数定义
def findIndex(templatePath: String, interest: String): Int = {
  val source = Source.fromFile(filePath, "UTF-8")
  val lines = source.getLines().toArray
  source.close()
  val searchMap = lines.zip(0 until lines.size).toMap
  searchMap.getOrElse(interest, -1)
}

//Dataset中的函数调用
findIndex(filePath, "体育-篮球-NBA-湖人")
```

我们可以看到这个函数有两个形参，一个是模板文件路径，另一个是训练样本中的用户兴趣。处理函数首先读取模板文件，然后根据文件中排序的字符串构建一个从兴趣到索引的 Map 映射，最后在这个 Map 中查找第二个形参传入的用户兴趣，如果能找到则返回对应的索引，找不到的话则返回 -1。

这段代码看上去似乎没什么问题，同学们基于上面的函数对千亿样本做 Label encoding，在 20 台机型为 C5.4xlarge AWS EC2 的分布式集群中花费了 5 个小时。坦白说，这样的执行性能，我是不能接受的。你可能会说：“需求就是这个样子，还能有什么别的办法呢？”我们不妨来看另外一种实现方式。

```scala
/**
	实现方式2
	输入参数：模板文件路径，用户兴趣字符串
	返回值：用户兴趣字符串对应的索引值
*/

//函数定义
val findIndex: (String) => (String) => Int = {
  (filePath) =>
  val source = Source.fromFile(filePath, "UTF-8")
  val lines = source.getLines().toArray
  source.close()
  val searchMap = lines.zip(0 until lines.size).toMap
  (interest) => searchMap.getOrElse(interest, -1)
}
val partFunc = findIndex(filePath)

//Dataset中的函数调用
partFunc("体育-篮球-NBA-湖人")
```

同学们基于第二种方式对相同的数据集做 Label encoding 之后，在 10 台同样机型的分布式集群中花了不到 20 分钟就把任务跑完了。可以说，执行性能的提升是显而易见的。那么，两份代码有什么区别呢？

我们可以看到，相比于第一份代码，第二份代码的函数体内没有任何变化，还是先读取模板文件、构建 Map 映射、查找用户兴趣，最后返回索引。最大的区别就是第二份代码对高阶函数的使用，具体来说有 2 点：

- 处理函数定义为高阶函数，形参是模板文件路径，返回结果是从用户兴趣到索引的函数；
- 封装千亿样本的 Dataset 所调用的函数，不是第一份代码中的 findIndex，而是用模板文件调用 findIndex 得到的 partFunc，partFunc 是形参为兴趣、结果为索引的普通标量函数。

## Spark 的调度系统是如何工作的？

Spark 调度系统的核心职责是，***先将用户构建的 DAG 转化为分布式任务，结合分布式集群资源的可用性，基于调度规则依序把分布式任务分发到执行器***。这个过程听上去就够复杂的了，为了方便你理解，我们还是先来讲一个小故事。

### 土豆工坊流水线升级

在学完了内存计算的第二层含义之后，土豆工坊的老板决定对土豆加工流水线做升级，来提高工坊的生产效率和灵活性。这里，我们先对内存计算的第二层含义做个简单地回顾，它指的是同一 Stage 中的所有操作会被捏合为一个函数，这个函数一次性会被地应用到输入数据上，并且一次性地产生计算结果。

这里，我们先对内存计算的第二层含义做个简单地回顾，它指的是同一 Stage 中的所有操作会被捏合为一个函数，这个函数一次性会被地应用到输入数据上，并且一次性地产生计算结果。

升级之前的土豆加工流程 DAG 被切分为 3 个执行阶段 Stage，它们分别是 Stage 0、Stage 1、Stage 2。其中，Stage 0 产出即食薯片，Stage 1 分发调味品，Stage 2 则产出不同尺寸、不同风味的薯片。我们重点关注 Stage 0，Stage 0 有 3 个加工环节，分别是清洗、切片和烘焙。这 3 个环节需要 3 种不同的设备，即清洗机、切片机和烤箱。

![](https://static001.geekbang.org/resource/image/3f/5f/3fcb3e400db91198a7499c016ccfb45f.jpg)

