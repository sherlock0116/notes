# 01 | 方案调研

## 一、方案调研

## 1.1 sql 解析

开始准备借助于 hive-exec 模块

```scala
val parser: ParseDriver = new ParseDriver
val astNode: ASTNode = parser.parse(sql)
val nonullASTNode: ASTNode = findRootNonNullToken(astNode)
println(nonullASTNode.toStringTree)
val sem: BaseSemanticAnalyzer = SemanticAnalyzerFactory.get(queryState, nonullASTNode)
sem.analyze(nonullASTNode, context)
val schema: Schema = getSchema(sem, hiveConf)
val queryPlan: QueryPlan = new QueryPlan(sql, sem, 0L, null, queryState.getHiveOperation, schema)
val result: String =
			s"""
			  |query: ${queryPlan.getQuery.toString}
			  |lineageInfo: ${queryPlan.getLineageInfo}
			  |operation: ${queryPlan.getOperation.getOperationName}
			  |inputs: ${queryPlan.getInputs.mkString}
			  |outputs: ${queryPlan.getOutputs.mkString}
			  |""".stripMargin
println(result)
```

如果拿到 QueryPlan 模块, 可以拿出目标 SQL 中的输入表和输出表以及表血缘关系 Lineage

但是 SemanticAnalyzerFactory 中需要 Hive 运行时的 SessionState 耦合度太高, 最终决定从方法 

QueryPlan#getInputs, QueryPlan#getOutputs, QueryPlan#getLineageInfo 入手改造部分代码。

## 1.2 如何获取 azkaban 中的 Hive sql?

这是个很棘手的问题, 初期想法是去解析 azkaban 的元数据库, 但其中大都以二进制和压缩的方法存储了, 所以最终决定使用 azkaban 的 AjaxRestful 来使用